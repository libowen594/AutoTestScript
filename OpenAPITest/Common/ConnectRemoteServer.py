#!/usr/bin/python
# -*- coding: UTF-8 -*-
__author__ = 'Bowen.li'

from time import sleep
import paramiko
from Common.logger import get_logger
from Common.ReadConfig import get_config_values
import json
import time
import os

logger = get_logger(__name__)


class ConnectRemoteServer:
    def __init__(self, server_name):
        self.host = get_config_values(server_name, "host")
        self.port = get_config_values(server_name, "port")
        self.user = get_config_values(server_name, "user")
        self.password = get_config_values(server_name, "password")
        self._transport = None

    def connect(self):
        try:
            transport = paramiko.Transport((self.host, int(self.port)))
            transport.connect(username=self.user, password=self.password)
            self._transport = transport
            logger.info(f"{self.host}è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"{self.host}è¿æ¥å¤±è´¥", str(e))

    def close(self):
        self._transport.close()
        logger.info(f"{self.host}è¿æ¥å·²æ–­å¼€")

    def getKafkaData(self, bbd_id, bbd_table):
        """
        è·å–ç¬¬ä¸€ä¸ªkafkaçš„æ•°æ®
        :param bbd_id: qyxx_idæˆ–xgxx_id
        :param bbd_table: éœ€è¦è·æ•°æ®çš„table_name
        :return:
        """

        logger.info(f'å¼€å§‹æ¶ˆè´¹kafkaæ•°æ®')
        count = 0
        cmd = 'kafka-console-consumer --zookeeper dataom102test6:2181,dataom102test8:2181,dataom102test10:2181/dataom102testkafka --topic bbd_queue_sync_20171121 --from-beginning |grep "{}"'.format(
            bbd_id)
        result = self.execute_cmd(cmd, timeout=5)
        lines = \
            [line for line in result.split("\n") if f'"bbd_table":"{bbd_table}"' in line and bbd_id in line]
        while len(lines) == 0 and count <= 3:
            result = self.execute_cmd(cmd, timeout=5)
            lines = \
                [line for line in result.split("\n") if f'"bbd_table":"{bbd_table}"' in line and bbd_id in line]
            count += 1
        else:
            if lines:
                line = lines[0]
                logger.info(f"kafkaæ¶ˆè´¹æ•°æ®{line}")
                return json.loads(line.replace("[01;31m[K", "").replace("[m[K", ""))
            else:
                return {}

    def getHbaseData(self, path, count=None, timeout=90):  # å¾ªç¯å–æ•°æ®ï¼Œè¶…è¿‡timeoutæ—¶é—´æ²¡æœ‰å–åˆ°å°±è¿”å›ç©º
        """
        :param path: hbaseè·¯å¾„
        :param count: ä¸Šä¸€æ¬¡æŸ¥è¯¢åˆ°çš„æ¡æ•°ï¼Œå¦‚æœä¸ä¼ å°±è¿”å›è·¯å¾„ä¸‹å½“å‰å­˜åœ¨æ•°æ®çš„æ¡æ•°
        :param timeout: è¶…æ—¶æ—¶é—´
        :return: æ–°å¢çš„æ•°æ®
        """
        cmd = rf'hadoop fs -cat {path}'
        start_time = time.time()
        result = self.execute_cmd(cmd, timeout=90)
        lines = [json.loads(line.replace("\r", "")) for line in result.split("\n") if '"data"' in line]
        if count is not None:
            while time.time() - start_time <= timeout:
                if len(lines) > count:
                    logger.info(f"æŸ¥æ‰¾åˆ°Hadoopå‚¨å­˜æ•°æ®,ç”¨æ—¶{time.time() - start_time}ç§’")
                    logger.info(f"hadoopå­˜å‚¨æ•°æ®{lines[count::]}")
                    return lines[count::]
                else:
                    time.sleep(3)
                    result = self.execute_cmd(cmd, timeout=90)
                    lines = [json.loads(line.replace("\r", "")) for line in result.split("\n") if '"data"' in line]
            else:
                print("\n")
                logger.info(f"hadoopå­˜å‚¨æ•°æ®{[]}")
                return []
        else:
            return len(lines)

    def upload(self, src_file, dsc_path):
        """
        ä¸Šä¼ æ–‡ä»¶
        :param src_file: æ–‡ä»¶æœ¬åœ°è·¯å¾„
        :param dsc_path: ä¸Šä¼ åˆ°æœåŠ¡å™¨çš„è·¯å¾„
        :return:
        """
        self.connect()
        sftp = paramiko.SFTPClient.from_transport(self._transport)
        path, filename = os.path.split(src_file)
        try:
            sftp.put(src_file, os.path.join(dsc_path, filename))
            logger.info(f"{src_file}ä¸Šä¼ æˆåŠŸ")
        except Exception as e:
            logger.info(f"{src_file}æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
            logger.error(e)
        sftp.close()
        self.close()

    def execute_cmd(self, cmd, timeout=None):
        """
        æ‰§è¡Œå‘½ä»¤
        :param cmd: éœ€è¦æ‰§è¡Œçš„å‘½ä»¤
        :param timeout: è¶…æ—¶æ—¶é—´ï¼Œè¶…è¿‡æ—¶é—´æ²¡æœ‰å–åˆ°æ•°æ®ï¼Œåˆ™è¿”å›å½“å‰æ‹¿åˆ°çš„æ•°æ®
        :return: è¿”å›å½“å‰å‘½ä»¤æ§åˆ¶å°æ‰“å°çš„å†…å®¹
        """
        self.connect()
        _channel = self._transport.open_session()
        if timeout and isinstance(timeout, int):
            _channel.settimeout(timeout)
        _channel.get_pty()
        _channel.invoke_shell()
        _channel.send(cmd + '\r')
        logger.info(f'æ‰§è¡Œå‘½ä»¤ï¼š{cmd}')
        result = ""
        while not result.endswith("$ "):  # å¾ªç¯è·å–æ§åˆ¶å°æ‰“å°çš„å†…å®¹
            try:
                sleep(0.5)
                ret = _channel.recv(65535)
                ret = ret.decode('utf-8', errors="ignore")
            except Exception:  # å‘ç”Ÿé”™è¯¯ï¼Œå°±åœæ­¢è·å–
                _channel.send("\x03")  # å‘é€ctrl+cåœæ­¢è¿è¡Œå‘½ä»¤
                time.sleep(2)
                _channel.close()
                logger.info(f'channelå…³é—­')
                self.close()
                return result
            else:
                result += ret  # æ²¡æœ‰å‘ç”Ÿé”™è¯¯å°±æŠŠå‰ä¸€æ¬¡è·å–çš„å†…å®¹æ‹¼æ¥åˆ°æ–°è·å–çš„å†…å®¹ä¸Š
        else:
            _channel.close()
            logger.info(f'channelå…³é—­')
            self.close()
            return result

    def start_app(self, query_cmd, cmd):
        """
        å¯åŠ¨ç¨‹åº
        :param query_cmd: æŸ¥çœ‹ç¨‹åºæ˜¯å¦å¯åŠ¨çš„å‘½ä»¤
        :param cmd: å¯åŠ¨ç¨‹åºçš„å‘½ä»¤
        :return: ç¨‹åºçš„pid
        """
        result = self.execute_cmd(query_cmd)
        line = [line.replace("\r", "") for line in result.split("\n") if "java" in line]
        while len(line) == 0:
            self.execute_cmd(cmd)
            time.sleep(1)
            result = self.execute_cmd(query_cmd)
            line = [line.replace("\r", "") for line in result.split("\n") if "java" in line]
        else:
            pid = line[0].split(" ")[3]
            name = line[0].split(" ")[-1]
            logger.info(f"ç¨‹åºå·²å¯åŠ¨ï¼Œname={name}, pid={pid}")
        return pid

    def start_app_offline(self, query_cmd, cmd):
        """
        å¯åŠ¨offlineæ¨é€ç¨‹åºï¼Œæ¨é€å®Œæˆä¹‹åï¼Œç¨‹åºä¼šè‡ªåŠ¨å…³é—­
        :param query_cmd: æ£€æŸ¥ç¨‹åºæ˜¯å¦å…³é—­çš„cmdå‘½ä»¤
        :param cmd: å¯åŠ¨ç¨‹åºçš„cmd
        :return: æ¨é€å®Œæˆä¹‹åè¿”å›True
        """
        logger.info("å¼€å§‹ç¦»çº¿æ¨é€æ•°æ®")
        result = self.execute_cmd(query_cmd)
        line = [line.replace("\r", "") for line in result.split("\n") if "java" in line]
        if len(line) != 0:
            pid = line[0].split(" ")[3]
            self.kill_app(pid)
            self.execute_cmd(cmd)
        else:
            self.execute_cmd(cmd)
        num = 1
        while num != 0:
            result = self.execute_cmd(query_cmd)
            num = len([line.replace("\r", "") for line in result.split("\n") if "java" in line])
            time.sleep(2)
        else:
            logger.info("ç¦»çº¿æ¨é€æ•°æ®å®Œæˆ")
            return True

    def kill_app(self, pid):
        """
        å…³é—­APP
        :param pid:ç¨‹åºçš„pid
        :return:
        """
        self.execute_cmd(f"kill -9 {pid}")
        logger.info(f"ç¨‹åºå·²å…³é—­ï¼Œpid={pid}")

    def start_app_spark(self, cmd, timeout=None):
        """
        å¯åŠ¨spark-offlineæ¨é€ç¨‹åº
        :param cmd: å¯åŠ¨å‘½ä»¤
        :param timeout: è¶…æ—¶æ—¶é—´ï¼Œå¤šå°‘æ—¶é—´åï¼Œæ§åˆ¶å°æ²¡æœ‰æ‰“å°æ–°çš„å†…å®¹ï¼Œåˆ™æ¨é€å®Œæˆ
        :return: æ§åˆ¶å°æ‰“å°çš„logä¿¡æ¯
        """
        logger.info("å¼€å§‹spark-offlineæ¨é€")
        app_path = get_config_values("SparkOffline-server", "app_path")
        self.connect()
        _channel = self._transport.open_session()
        if timeout and isinstance(timeout, int):
            _channel.settimeout(timeout)
        _channel.get_pty()
        _channel.invoke_shell()
        _channel.send(f"cd {app_path}" + '\r')
        logger.info(f'è¿›å…¥ç¨‹åºæ‰€åœ¨è·¯å¾„')
        _channel.send(cmd + "\r")
        logger.info(f"æ‰§è¡Œå‘½ä»¤:{cmd},å¯åŠ¨æ¨é€ç¨‹åº")
        result = ""
        while not result.endswith("$ "):
            try:
                sleep(0.5)
                ret = _channel.recv(65535)
                ret = ret.decode('utf-8')
            except Exception:
                _channel.send("\x03")  # å‘é€ctrl+cåœæ­¢è¿è¡Œå‘½ä»¤
                time.sleep(timeout)
                _channel.close()
                logger.info(f'channelå…³é—­')
                self.close()
                return result
            else:
                result += ret
        else:
            _channel.close()
            logger.info(f'channelå…³é—­')
            self.close()
            return result


if __name__ == '__main__':
    ConnectRemoteServer(server_name="AutoPushApp-server").upload(
        src_file=r"D:\pythonProject\OpenAPITest\TestData\2021-04-27\OfflineAutoPush\test_data.csv",
        dsc_path=r"/data1/dataom/dp-huangyujun/autopush/autopush-offline/")
